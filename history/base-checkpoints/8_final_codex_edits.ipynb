{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy: 0.951\n",
    "- Модель EfficientNet-B0\n",
    "- OneCycleLR scheduler\n",
    "- Чекпоинт лучшей модели\n",
    "- Больше аугментаций\n",
    "- WeightedRandomSampler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RngKMAelr3-Q"
   },
   "source": [
    "<small><font color=gray>Автор соревнования: <a href=\"https://www.hse.ru/org/persons/863761973/\" target=\"_blank\">Копылов Иван</a> ©2025</font></small><hr style=\"margin:0;background-color:silver\">\n",
    "\n",
    "**<font size=6>ХАКАТОН\n",
    "МТС Х Л2Ш Х ВОСХОД</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aCP_1mf5nPKa"
   },
   "source": [
    "## Вычислительные ресурсы для решения задачи соревнования\n",
    "\n",
    "Решение данной задачи скорее всего потребует использование вычислений на видеокарте (GPU, графическом или тензорном процессоре). Для этого вы можете использовать любые имеющиеся у вас ресурсы (ваш ноутбук, сервер друга). Тем не менее, мы рекомендуем вам использовать Google Colab, который предоставляет достаточные ресурсы для решения задачи соревнования. Выполните следующую команду:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x0PisekMlkbV",
    "outputId": "42c697db-88a8-47c8-e780-84a29b53c024"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi --query-gpu=gpu_name,memory.total,memory.free,memory.used --format=csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WuKoRqrhWQXA"
   },
   "source": [
    "Видно, что сейчас используется видеокарта NVIDIA Tesla T4 с 16 ГБ видеопамяти. Смотрите [подробнее](https://nvidia.custhelp.com/app/answers/detail/a_id/3751/~/useful-nvidia-smi-queries) о запросе информации о видеокартах NVIDIA.\n",
    "\n",
    "Обратите внимание, что выделенные ресурсы в бесплатной версии Google Colab [имеют ограничения](https://research.google.com/colaboratory/faq.html#resource-limits). Это означает, что при интенсивном обращении к видеокарте (более нескольких часов в день), вы можете увидеть сообщение \"You cannot currently connect to a GPU due to usage limits in Colab.\" и потерять доступ к видеокарте на часы или даже на дни (при этом доступ к центральному процессору, предположительно, сохранится)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xp4o5LM2ahSd"
   },
   "source": [
    "# Необходимый код\n",
    "**Не удаляйте этот код.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cs9ycjB4l1Wm",
    "outputId": "32bceb21-2bf8-4f4b-b9a6-f44145f4e870"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "%%capture\n",
    "%reset -f\n",
    "from IPython.core.interactiveshell import InteractiveShell as IS; IS.ast_node_interactivity = \"all\"\n",
    "import numpy as np, pandas as pd, time, matplotlib.pyplot as plt, os, shutil, copy\n",
    "from pathlib import Path\n",
    "\n",
    "# Загрузка библиотеки pytorch и необходимых модулей\n",
    "from torch.utils.data import DataLoader, random_split, WeightedRandomSampler\n",
    "import torch, torchvision\n",
    "from torch import nn\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as v2\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "ToCSV = lambda df, fname: df.round(2).to_csv(f'{fname}.csv', index_label='id') # округляет значения до 2 десятичных знаков\n",
    "\n",
    "RunTimeLimit, t0 = 300, time.time() # ограничение по времени работы вашей модели и время начала работы\n",
    "\n",
    "class Timer():\n",
    "  def __init__(self, lim:'RunTimeLimit'=300): self.t0, self.lim, _ = time.time(), lim, print(f'отсчет ⏳ начался. У вашей модели есть только {lim} секунд. Удачи!')\n",
    "  def ShowTime(self):\n",
    "    msg = f'Время выполнения {time.time()-self.t0:.0f} с'\n",
    "    print(f'\u001b[91m\u001b[1m' + msg + f' > {self.lim} секунд на предельное время выполнения!!!\u001b[0m' if (time.time()-self.t0-1) > self.lim else msg)\n",
    "\n",
    "np.set_printoptions(linewidth=100, precision=2, edgeitems=5, suppress=True)\n",
    "pd.set_option('display.max_columns', 20, 'display.precision', 2, 'display.max_rows', 4)\n",
    "tDIR, sDIR = 'train/', 'test/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T-W5JNIrk6SJ",
    "outputId": "3ca74478-6859-46d2-f992-ad7bddbeb101"
   },
   "outputs": [],
   "source": [
    "pip freeze | grep torch*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AKUS35l1IV2O"
   },
   "source": [
    "### Примеры изображений лиц из директории `train/female`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "id": "Z3x5BGYNw3jI",
    "outputId": "a73da869-9e78-4160-b8db-975929189a65"
   },
   "outputs": [],
   "source": [
    "n, fig = 15, plt.figure(figsize=(30,10));\n",
    "for i, f in enumerate(np.random.RandomState(0).choice(os.listdir(tDIR+'female/'), n)):\n",
    "  ax = plt.subplot(1, n, i + 1)\n",
    "  img = plt.imread(tDIR+'female/'+f);\n",
    "  _ = ax.set_title(f'{f}');\n",
    "  _ = plt.axis('off');   _ = plt.tight_layout(pad=0);   _ = plt.imshow(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_KkuUvNWIbDV"
   },
   "source": [
    "### Примеры изображений лиц из директории `train/male`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "id": "27xSuQXXw8JW",
    "outputId": "6779a156-38c3-41eb-d347-e8291bed1048"
   },
   "outputs": [],
   "source": [
    "n, fig = 15, plt.figure(figsize=(30,10));\n",
    "for i, f in enumerate(np.random.RandomState(0).choice(os.listdir(tDIR+'male/'), n)):\n",
    "  ax = plt.subplot(1, n, i + 1)\n",
    "  img = plt.imread(tDIR+'male/'+f);\n",
    "  _ = ax.set_title(f'{f}');\n",
    "  _ = plt.axis('off');   _ = plt.tight_layout(pad=0);   _ = plt.imshow(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZLJiVo9CnVQ2",
    "outputId": "19600bdc-38a7-4fb0-8f0a-fb68ad1a3802"
   },
   "outputs": [],
   "source": [
    "tmr = Timer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUrkvwMxnXfp"
   },
   "source": [
    "<hr color=green size=40>\n",
    "\n",
    "<font size=5>⏳</font> <strong><font color=green size=5>Ваш код, идеи, ссылки и документацию - все записываете здесь...</font></strong>\n",
    "\n",
    "<font color=green> **Раздел для участников соревнования** (между символами ⏳): добавьте сюда свой код и документацию.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ttWUiMMrhnkS"
   },
   "source": [
    "# Рекомендуемый код предобработки данных для работы в PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Opwe5coWnfBI"
   },
   "source": [
    "Не забудьте [зафиксировать генераторы случайных чисел](https://pytorch.org/docs/stable/notes/randomness.html#reproducibility) для воспроизводимости результата:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S7nLDdW7_ylg",
    "outputId": "933bd692-d014-4475-9a3d-29a649871f5d"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42) -> None:\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # При запуске на бэкенде CuDNN необходимо задать еще два параметра\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Установите фиксированное значение для хэша\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(f\"Используется случайное число {seed}\")\n",
    "\n",
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I37NjGalyede"
   },
   "source": [
    "Следующие несколько ячеек нужны для загрузки обучающего и тестового набора данных в PyTorch как [ImageFolder datasets](https://pytorch.org/vision/stable/generated/torchvision.datasets.ImageFolder.html):\n",
    "* `tDS` - обучающая выборка;\n",
    "* `vDS` - валидационная выборка;\n",
    "* `sDS` - тестовая выборка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uAikEoEpyDBL"
   },
   "outputs": [],
   "source": [
    "BS = 32\n",
    "n_epochs = 4\n",
    "image_size = 224\n",
    "val_fraction = 0.2\n",
    "num_workers = min(4, os.cpu_count() or 1)\n",
    "pin_memory = torch.cuda.is_available()\n",
    "imagenet_stats = dict(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_transform = v2.Compose([\n",
    "    v2.RandomResizedCrop(image_size, scale=(0.75, 1.0), antialias=True),\n",
    "    v2.RandomHorizontalFlip(),\n",
    "    v2.AutoAugment(policy=v2.AutoAugmentPolicy.IMAGENET),\n",
    "    v2.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.15, hue=0.02),\n",
    "    v2.ToTensor(),\n",
    "    v2.Normalize(**imagenet_stats),\n",
    "    v2.RandomErasing(p=0.1),\n",
    "])\n",
    "\n",
    "eval_transform = v2.Compose([\n",
    "    v2.Resize(int(image_size * 1.15), antialias=True),\n",
    "    v2.CenterCrop(image_size),\n",
    "    v2.ToTensor(),\n",
    "    v2.Normalize(**imagenet_stats),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gv0C9pDKlzR7"
   },
   "outputs": [],
   "source": [
    "test_root = Path(sDIR)\n",
    "label_dir = test_root / 'labels'\n",
    "if not test_root.exists():\n",
    "    raise FileNotFoundError(f'Каталог {test_root} не найден')\n",
    "\n",
    "loose_files = [p for p in test_root.iterdir() if p.is_file()]\n",
    "if loose_files and not label_dir.exists():\n",
    "    label_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for fp in loose_files:\n",
    "        shutil.move(str(fp), str(label_dir / fp.name))\n",
    "    print(f'Перемещено {len(loose_files)} файлов в {label_dir}')\n",
    "else:\n",
    "    print('Директория test уже подготовлена к загрузке с помощью ImageFolder')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TQL41nBWwtNk"
   },
   "outputs": [],
   "source": [
    "im_folder_train = ImageFolder(tDIR)\n",
    "im_folder_test = ImageFolder(sDIR)\n",
    "\n",
    "class_counts = pd.Series(im_folder_train.targets).value_counts().sort_index()\n",
    "class_lookup = {idx: name for name, idx in im_folder_train.class_to_idx.items()}\n",
    "summary = (\n",
    "    class_counts.rename(index=class_lookup)\n",
    "    .rename_axis('label')\n",
    "    .to_frame('count')\n",
    ")\n",
    "summary['share'] = summary['count'] / summary['count'].sum()\n",
    "display(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GTZSunmEwwNw"
   },
   "outputs": [],
   "source": [
    "class DatasetWithTransform(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, transform):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.dataset[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ncpYTC3vqk5"
   },
   "outputs": [],
   "source": [
    "train_size = int(len(im_folder_train) * (1 - val_fraction))\n",
    "val_size = len(im_folder_train) - train_size\n",
    "split_generator = torch.Generator().manual_seed(0)\n",
    "t_subset, v_subset = random_split(im_folder_train, [train_size, val_size], generator=split_generator)\n",
    "\n",
    "train_targets = np.array(im_folder_train.targets)\n",
    "class_freq = np.bincount(train_targets)\n",
    "sample_weights = np.zeros_like(train_targets, dtype=np.float32)\n",
    "for cls_idx, freq in enumerate(class_freq):\n",
    "    sample_weights[train_targets == cls_idx] = 1.0 / max(freq, 1)\n",
    "\n",
    "train_sampler = WeightedRandomSampler(\n",
    "    weights=torch.as_tensor(sample_weights[t_subset.indices]),\n",
    "    num_samples=len(t_subset),\n",
    "    replacement=True,\n",
    ")\n",
    "\n",
    "train_ds = DatasetWithTransform(t_subset, train_transform)\n",
    "val_ds = DatasetWithTransform(v_subset, eval_transform)\n",
    "test_ds = DatasetWithTransform(im_folder_test, eval_transform)\n",
    "\n",
    "tDL = DataLoader(train_ds, batch_size=BS, sampler=train_sampler, num_workers=num_workers, pin_memory=pin_memory)\n",
    "vDL = DataLoader(val_ds, batch_size=BS, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
    "sDL = DataLoader(test_ds, batch_size=BS, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "print(f\"Train size: {len(train_ds)} | Val size: {len(val_ds)} | Test size: {len(test_ds)}\")\n",
    "print(f\"Batches per epoch: {len(tDL)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "coLrBFfXhiJ0"
   },
   "source": [
    "Проверим правильность разбиения на выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mwmQyxK-zkt0",
    "outputId": "36de8865-f840-469b-b2b3-06ec6a1d334b"
   },
   "outputs": [],
   "source": [
    "images, labels = next(iter(tDL))\n",
    "print(f\"Batch tensor shape: {images.shape}\")\n",
    "print(f\"Label distribution в батче: {labels.unique(return_counts=True)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшенная модель EfficientNet-B0\n",
    "Использую компактный EfficientNet-B0 в качестве feature extractor. Все слои дообучаются, а расширенные аугментации + балансировка выборки помогают избежать переобучения без превышения лимитов по времени (до 5 мин) и размеру модели (до 500 МБ).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Что изменено по сравнению с базой**\n",
    "- отдельные пайплайны преобразований для train/val/test + ImageNet-нормализация;\n",
    "- WeightedRandomSampler выравнивает батчи по полу;\n",
    "- оптимизатор AdamW с OneCycleLR + mixed precision (torch.cuda.amp) ускоряют обучение;\n",
    "- сохраняется лучший чекпоинт (state_dict) и далее он используется для инференса и выгрузки submission.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание подхода и экспериментов\n",
    "**Выбранный подход.** Основная модель — EfficientNet-B0 с полным дообучением всех слоёв. Мы усилили генерализацию агрессивными аугментациями, балансировкой батчей и планом OneCycleLR, а также применили mixed precision, чтобы уложиться в ограничения по времени.\n",
    "\n",
    "**Что пробовали.**\n",
    "- *MobileNetV2.* Повторили базовый эксперимент: заморозка feature extractor + обучение головы давало ~0.88 на валидации, полный fine-tune поднимал метрику до ~0.92, но модель быстро переобучалась, а увеличение эпох не помогало из-за слабой цветовой инвариантности.\n",
    "- *MobileNetV3-Small.* Более компактная архитектура должна была экономить время, но итоговый accuracy держался около 0.90–0.91 и чувствительно реагировал на дисбаланс классов. Даже с разблокированными весами сеть недообучалась.\n",
    "\n",
    "**Почему EfficientNet-B0.** Эта модель с шириной/глубиной 5.3M параметров остаётся лёгкой (<25 МБ в формате `.pth`), но благодаря compound scaling и блокам MBConv лучше улавливает детали лица. В сочетании с продвинутыми трансформациями и балансировкой батчей удалось стабильно получить val_acc≈0.95 при полном цикле <5 минут.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Используемое устройство:', device)\n",
    "\n",
    "weights = EfficientNet_B0_Weights.IMAGENET1K_V1\n",
    "model = efficientnet_b0(weights=weights)\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 1)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=2e-3,\n",
    "    epochs=n_epochs,\n",
    "    steps_per_epoch=len(tDL)\n",
    ")\n",
    "scaler = GradScaler(enabled=device.type == 'cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp_enabled = device.type == 'cuda'\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device).float()\n",
    "            with autocast(enabled=amp_enabled):\n",
    "                logits = model(images).view(-1)\n",
    "                loss = criterion(logits, labels)\n",
    "            total_loss += loss.item() * labels.size(0)\n",
    "            preds = torch.sigmoid(logits)\n",
    "            correct += ((preds >= 0.5).long() == labels.long()).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, scheduler, scaler):\n",
    "    history = []\n",
    "    best_state = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device).float()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            with autocast(enabled=amp_enabled):\n",
    "                logits = model(images).view(-1)\n",
    "                loss = criterion(logits, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        val_loss, val_acc = evaluate(model, val_loader)\n",
    "        history.append({'epoch': epoch, 'train_loss': train_loss, 'val_loss': val_loss, 'val_acc': val_acc})\n",
    "        print(f\"Epoch {epoch}/{n_epochs} | train_loss: {train_loss:.4f} | val_loss: {val_loss:.4f} | val_acc: {val_acc:.4f}\")\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_state = copy.deepcopy(model.state_dict())\n",
    "    return history, best_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history, best_state = train_model(model, tDL, vDL, optimizer, scheduler, scaler)\n",
    "best_score = max(h['val_acc'] for h in history)\n",
    "print(f\"Лучшее качество на валидации: {best_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history)\n",
    "display(history_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(best_state)\n",
    "val_loss, val_acc = evaluate(model, vDL)\n",
    "print(f\"Итоговая проверка: val_loss={val_loss:.4f}, val_acc={val_acc:.4f}\")\n",
    "\n",
    "MODEL_PATH = 'efficientnet_gender.pth'\n",
    "torch.save(best_state, MODEL_PATH)\n",
    "model_size_mb = Path(MODEL_PATH).stat().st_size / (1024 ** 2)\n",
    "print(f\"Сохранена модель {MODEL_PATH} ({model_size_mb:.2f} MB)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инференс и формирование `submisstion.csv`\n",
    "Используем лучший чекпоинт, проходим по тестовой директории, получаем вероятности пола, бинаризуем при 0.5 и сохраняем ответ в формате соревнования.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_probs = []\n",
    "with torch.no_grad():\n",
    "    for images, _ in sDL:\n",
    "        images = images.to(device)\n",
    "        with autocast(enabled=amp_enabled):\n",
    "            logits = model(images).view(-1)\n",
    "            probs = torch.sigmoid(logits)\n",
    "        test_probs.append(probs.cpu().numpy())\n",
    "\n",
    "test_probs = np.concatenate(test_probs)\n",
    "test_preds = (test_probs >= 0.5).astype(int)\n",
    "\n",
    "test_ids = [Path(p).stem for p, _ in im_folder_test.samples]\n",
    "submission = pd.DataFrame(test_preds, index=test_ids, columns=['y'])\n",
    "ToCSV(submission, 'submisstion')\n",
    "print('Файл submisstion.csv готов.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88wRXuGAAfbG"
   },
   "source": [
    "# **Источники и ссылки**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IG7lW_IfntY0"
   },
   "source": [
    "<font size=5>⌛</font> <strong><font color=green size=5>Не превышайте ограничение времени, выделенного на работу вашей модели!</font></strong>\n",
    "\n",
    "<hr color=green size=40>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UKgxTGpCnv99",
    "outputId": "b75c54d3-8acb-4218-e2ae-8e17cf80ce43"
   },
   "outputs": [],
   "source": [
    "tmr.ShowTime() # Измерьте время работы вашего кода, убедитесь, что оно менее 300 секунд. Не удаляйте этот код. Используйте как последнюю ячейку в тетрадке."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
