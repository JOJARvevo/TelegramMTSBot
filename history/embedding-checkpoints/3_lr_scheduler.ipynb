{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Accuracy: 0.987\n",
        "- LR scheduler\n",
        "- Изменения аугментаций"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RngKMAelr3-Q"
      },
      "source": [
        "<small><font color=gray>Автор соревнования: <a href=\"https://www.hse.ru/org/persons/863761973/\" target=\"_blank\">Копылов Иван</a> ©2025</font></small><hr style=\"margin:0;background-color:silver\">\n",
        "\n",
        "**<font size=6>ХАКАТОН\n",
        "МТС Х Л2Ш Х ВОСХОД</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCP_1mf5nPKa"
      },
      "source": [
        "## Вычислительные ресурсы для решения задачи соревнования\n",
        "\n",
        "Решение данной задачи скорее всего потребует использование вычислений на видеокарте (GPU, графическом или тензорном процессоре). Для этого вы можете использовать любые имеющиеся у вас ресурсы (ваш ноутбук, сервер друга). Тем не менее, мы рекомендуем вам использовать Google Colab, который предоставляет достаточные ресурсы для решения задачи соревнования. Выполните следующую команду:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0PisekMlkbV",
        "outputId": "42c697db-88a8-47c8-e780-84a29b53c024"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi --query-gpu=gpu_name,memory.total,memory.free,memory.used --format=csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuKoRqrhWQXA"
      },
      "source": [
        "Видно, что сейчас используется видеокарта NVIDIA Tesla T4 с 16 ГБ видеопамяти. Смотрите [подробнее](https://nvidia.custhelp.com/app/answers/detail/a_id/3751/~/useful-nvidia-smi-queries) о запросе информации о видеокартах NVIDIA.\n",
        "\n",
        "Обратите внимание, что выделенные ресурсы в бесплатной версии Google Colab [имеют ограничения](https://research.google.com/colaboratory/faq.html#resource-limits). Это означает, что при интенсивном обращении к видеокарте (более нескольких часов в день), вы можете увидеть сообщение \"You cannot currently connect to a GPU due to usage limits in Colab.\" и потерять доступ к видеокарте на часы или даже на дни (при этом доступ к центральному процессору, предположительно, сохранится)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xp4o5LM2ahSd"
      },
      "source": [
        "# Необходимый код\n",
        "**Не удаляйте этот код.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cs9ycjB4l1Wm",
        "outputId": "32bceb21-2bf8-4f4b-b9a6-f44145f4e870"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "%%capture\n",
        "%reset -f\n",
        "from IPython.core.interactiveshell import InteractiveShell as IS; IS.ast_node_interactivity = \"all\"\n",
        "import numpy as np, pandas as pd, time, matplotlib.pyplot as plt, os # загрузка основных библиотек для работы с данными\n",
        "\n",
        "# Загрузка библиотеки pytorch и необходимых модулей\n",
        "import torch, torchvision\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torch import nn\n",
        "from torch.nn import Sequential, Flatten, Linear, LazyLinear, Dropout, AdaptiveAvgPool2d, MaxPool2d, Conv2d, AvgPool2d\n",
        "\n",
        "# from torchvision.models import resnet50, mobilenet_v2\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as v2\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "\n",
        "ToCSV = lambda df, fname: df.round(2).to_csv(f'{fname}.csv', index_label='id') # округляет значения до 2 десятичных знаков\n",
        "\n",
        "RunTimeLimit, t0 = 300, time.time() # ограничение по времени работы вашей модели и время начала работы\n",
        "\n",
        "class Timer():\n",
        "  def __init__(self, lim:'RunTimeLimit'=300): self.t0, self.lim, _ = time.time(), lim, print(f'отсчет ⏳ начался. У вашей модели есть только {lim} секунд. Удачи!')\n",
        "  def ShowTime(self):\n",
        "    msg = f'Время выполнения {time.time()-self.t0:.0f} с'\n",
        "    print(f'\\033[91m\\033[1m' + msg + f' > {self.lim} секунд на предельное время выполнения!!!\\033[0m' if (time.time()-self.t0-1) > self.lim else msg)\n",
        "\n",
        "np.set_printoptions(linewidth=100, precision=2, edgeitems=5, suppress=True)\n",
        "pd.set_option('display.max_columns', 20, 'display.precision', 2, 'display.max_rows', 4)\n",
        "tDIR, sDIR = 'train/', 'test/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-W5JNIrk6SJ",
        "outputId": "3ca74478-6859-46d2-f992-ad7bddbeb101"
      },
      "outputs": [],
      "source": [
        "# pip freeze | grep torch*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKUS35l1IV2O"
      },
      "source": [
        "### Примеры изображений лиц из директории `train/female`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "Z3x5BGYNw3jI",
        "outputId": "a73da869-9e78-4160-b8db-975929189a65"
      },
      "outputs": [],
      "source": [
        "n, fig = 15, plt.figure(figsize=(30,10));\n",
        "for i, f in enumerate(np.random.RandomState(0).choice(os.listdir(tDIR+'female/'), n)):\n",
        "  ax = plt.subplot(1, n, i + 1)\n",
        "  img = plt.imread(tDIR+'female/'+f);\n",
        "  _ = ax.set_title(f'{f}');\n",
        "  _ = plt.axis('off');   _ = plt.tight_layout(pad=0);   _ = plt.imshow(img);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KkuUvNWIbDV"
      },
      "source": [
        "### Примеры изображений лиц из директории `train/male`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "27xSuQXXw8JW",
        "outputId": "6779a156-38c3-41eb-d347-e8291bed1048"
      },
      "outputs": [],
      "source": [
        "n, fig = 15, plt.figure(figsize=(30,10));\n",
        "for i, f in enumerate(np.random.RandomState(0).choice(os.listdir(tDIR+'male/'), n)):\n",
        "  ax = plt.subplot(1, n, i + 1)\n",
        "  img = plt.imread(tDIR+'male/'+f);\n",
        "  _ = ax.set_title(f'{f}');\n",
        "  _ = plt.axis('off');   _ = plt.tight_layout(pad=0);   _ = plt.imshow(img);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLJiVo9CnVQ2",
        "outputId": "19600bdc-38a7-4fb0-8f0a-fb68ad1a3802"
      },
      "outputs": [],
      "source": [
        "tmr = Timer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUrkvwMxnXfp"
      },
      "source": [
        "<hr color=green size=40>\n",
        "\n",
        "<font size=5>⏳</font> <strong><font color=green size=5>Ваш код, идеи, ссылки и документацию - все записываете здесь...</font></strong>\n",
        "\n",
        "<font color=green> **Раздел для участников соревнования** (между символами ⏳): добавьте сюда свой код и документацию.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7nLDdW7_ylg",
        "outputId": "933bd692-d014-4475-9a3d-29a649871f5d"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed: int = 42) -> None:\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    print(f\"Используется случайное число {seed}\")\n",
        "\n",
        "set_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def getDevice():\n",
        "    if torch.cuda.is_available():\n",
        "        return 'cuda'\n",
        "    elif torch.backends.mps.is_available():\n",
        "        return 'mps'\n",
        "    else:\n",
        "        return 'cpu'\n",
        "\n",
        "DEVICE = getDevice()\n",
        "print(\"Используем\", DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "IMAGE_SIZE = 160\n",
        "CLASSIFIER_EPOCHS = 100\n",
        "CLASSIFIER_LR = 1e-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from facenet_pytorch import InceptionResnetV1\n",
        "\n",
        "train_transform = v2.Compose([\n",
        "    v2.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    v2.RandomHorizontalFlip(p=0.5),\n",
        "    v2.RandomRotation(degrees=3),\n",
        "    v2.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
        "    v2.ToTensor(),\n",
        "    v2.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "test_transform = v2.Compose([\n",
        "    v2.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    v2.ToTensor(),\n",
        "    v2.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = ImageFolder('train/', transform=train_transform)\n",
        "test_dataset = ImageFolder('test/', transform=test_transform)\n",
        "\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_ds, val_ds = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "facenet = InceptionResnetV1(pretrained='vggface2').eval().to(DEVICE);\n",
        "\n",
        "def extract_embeddings(model, dataloader, desc=\"Extracting\"):\n",
        "    embeddings_list = []\n",
        "    labels_list = []\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (images, labels) in enumerate(dataloader):\n",
        "            images = images.to(DEVICE)\n",
        "            emb = model(images)\n",
        "            embeddings_list.append(emb.cpu())\n",
        "            labels_list.append(labels)\n",
        "            \n",
        "            if batch_idx % 20 == 0:\n",
        "                print(f\"{desc}: batch {batch_idx}/{len(dataloader)}\")\n",
        "    \n",
        "    embeddings = torch.cat(embeddings_list, dim=0)\n",
        "    labels = torch.cat(labels_list, dim=0)\n",
        "    return embeddings, labels\n",
        "\n",
        "train_embeddings, train_labels = extract_embeddings(facenet, train_loader, \"Train\")\n",
        "val_embeddings, val_labels = extract_embeddings(facenet, val_loader, \"Validation\")\n",
        "test_embeddings, _ = extract_embeddings(facenet, test_loader, \"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "class EmbeddingClassifier(nn.Module):\n",
        "    def __init__(self, input_dim=512, hidden_dim=256, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(hidden_dim),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, 1)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.classifier(x)\n",
        "\n",
        "classifier = EmbeddingClassifier(input_dim=512, hidden_dim=256, dropout=0.3).to(DEVICE)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.AdamW(classifier.parameters(), lr=CLASSIFIER_LR, weight_decay=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_emb_ds = torch.utils.data.TensorDataset(train_embeddings, train_labels)\n",
        "val_emb_ds = torch.utils.data.TensorDataset(val_embeddings, val_labels)\n",
        "\n",
        "train_emb_loader = DataLoader(train_emb_ds, batch_size=128, shuffle=True)\n",
        "val_emb_loader = DataLoader(val_emb_ds, batch_size=128, shuffle=False)\n",
        "\n",
        "best_val_acc = 0\n",
        "best_epoch = 0\n",
        "best_model_state = None\n",
        "history = {'train_loss': [], 'val_acc': []}\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "    optimizer, \n",
        "    max_lr=CLASSIFIER_LR * 10,\n",
        "    epochs=CLASSIFIER_EPOCHS, \n",
        "    steps_per_epoch=len(train_emb_loader),\n",
        "    pct_start=0.3,\n",
        "    anneal_strategy='cos',\n",
        "    final_div_factor=100\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for epoch in range(CLASSIFIER_EPOCHS):\n",
        "    # training\n",
        "    _ = classifier.train()\n",
        "    train_loss = 0\n",
        "    for embeddings, labels in train_emb_loader:\n",
        "        embeddings, labels = embeddings.to(DEVICE), labels.to(DEVICE).float()\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = classifier(embeddings).squeeze()\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        train_loss += loss.item()\n",
        "    \n",
        "    avg_train_loss = train_loss / len(train_emb_loader)\n",
        "    \n",
        "    # validation\n",
        "    _ = classifier.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for embeddings, labels in val_emb_loader:\n",
        "            embeddings, labels = embeddings.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = classifier(embeddings).squeeze()\n",
        "            predictions = (torch.sigmoid(outputs) > 0.5).long()\n",
        "            correct += (predictions == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    \n",
        "    val_acc = correct / total\n",
        "    # scheduler.step(val_acc)\n",
        "\n",
        "    history['train_loss'].append(avg_train_loss)\n",
        "    history['val_acc'].append(val_acc)\n",
        "    \n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        best_epoch = epoch\n",
        "        best_model_state = classifier.state_dict().copy()\n",
        "    \n",
        "    if epoch % 10 == 0 or epoch == CLASSIFIER_EPOCHS - 1:\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        print(f\"Эпоха {epoch:3d}/{CLASSIFIER_EPOCHS} | loss: {avg_train_loss:.4f} | acc: {val_acc:.4f} | lr: {current_lr:.6f} | best: {best_val_acc:.4f}\")\n",
        "\n",
        "print(f\"Наибольшая точность: {best_val_acc:.4f} (Эпоха {best_epoch})\")\n",
        "\n",
        "classifier.load_state_dict(best_model_state)\n",
        "torch.save(best_model_state, 'best.pth')\n",
        "\n",
        "_ = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classifier.eval()\n",
        "test_predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(0, len(test_embeddings), 128):\n",
        "        batch_emb = test_embeddings[i:i+128].to(DEVICE)\n",
        "        outputs = classifier(batch_emb).squeeze()\n",
        "        probs = torch.sigmoid(outputs).cpu().numpy()\n",
        "        test_predictions.append(probs)\n",
        "\n",
        "test_predictions = np.concatenate(test_predictions)\n",
        "\n",
        "# Get test file IDs\n",
        "test_ids = [os.path.splitext(os.path.basename(path))[0] for path, _ in test_dataset.imgs]\n",
        "\n",
        "# Create submission DataFrame\n",
        "submission = pd.DataFrame({\n",
        "    'y': (test_predictions > 0.5).astype(int)\n",
        "}, index=test_ids)\n",
        "\n",
        "# Save to CSV\n",
        "output_file = 'submission.csv'\n",
        "submission.to_csv(output_file, index_label='id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Final accuracy: {best_val_acc:.3%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88wRXuGAAfbG"
      },
      "source": [
        "# **Источники и ссылки**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IG7lW_IfntY0"
      },
      "source": [
        "<font size=5>⌛</font> <strong><font color=green size=5>Не превышайте ограничение времени, выделенного на работу вашей модели!</font></strong>\n",
        "\n",
        "<hr color=green size=40>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKgxTGpCnv99",
        "outputId": "b75c54d3-8acb-4218-e2ae-8e17cf80ce43"
      },
      "outputs": [],
      "source": [
        "tmr.ShowTime() # Измерьте время работы вашего кода, убедитесь, что оно менее 300 секунд. Не удаляйте этот код. Используйте как последнюю ячейку в тетрадке."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
